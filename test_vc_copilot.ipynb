{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VC Copilot Feature Testing Notebook\n",
    "\n",
    "This notebook allows you to test the VC Copilot backend features directly, including:\n",
    "1. Website scraping\n",
    "2. SWOT analysis\n",
    "3. Deep dive analysis\n",
    "4. Founder evaluation\n",
    "\n",
    "Let's start by importing the necessary functions from the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "import asyncio\n",
    "\n",
    "# Add the backend directory to the path so we can import from it\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "\n",
    "# Import the necessary functions from the backend\n",
    "from backend.main import scrape_website, analyze_data, run_deep_dive_analysis, evaluate_founders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Website Scraping\n",
    "\n",
    "First, let's test the website scraping functionality. This will extract basic information about a startup from its website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to run async functions in the notebook\n",
    "async def run_async(coroutine):\n",
    "    return await coroutine\n",
    "\n",
    "# Test URLs\n",
    "test_urls = [\n",
    "    \"https://www.helix-db.com\",\n",
    "    \"https://openai.com\",\n",
    "    \"https://anthropic.com\",\n",
    "    \"https://stripe.com\"\n",
    "]\n",
    "\n",
    "# Select a URL to test\n",
    "test_url = test_urls[0]  # Change index to test different URLs\n",
    "print(f\"Scraping data from: {test_url}\")\n",
    "\n",
    "# Scrape website data\n",
    "scraped_data = await run_async(scrape_website(test_url))\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Company Name: {scraped_data.company_name}\")\n",
    "print(f\"Description: {scraped_data.description[:200]}...\")\n",
    "print(f\"Team Info: {scraped_data.team_info}\")\n",
    "print(f\"Technologies: {scraped_data.technologies}\")\n",
    "print(f\"Social Links: {scraped_data.social_links}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SWOT Analysis\n",
    "\n",
    "Now, let's run a basic SWOT analysis on the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SWOT analysis\n",
    "analysis_result = await run_async(analyze_data(scraped_data, [\"swot\"]))\n",
    "\n",
    "# Display SWOT analysis results\n",
    "print(f\"Company: {analysis_result.company_name}\")\n",
    "print(f\"Industry: {analysis_result.industry}\")\n",
    "print(f\"Score: {analysis_result.score}/10\")\n",
    "print(\"\\nStrengths:\")\n",
    "for strength in analysis_result.strengths:\n",
    "    print(f\"- {strength}\")\n",
    "    \n",
    "print(\"\\nWeaknesses:\")\n",
    "for weakness in analysis_result.weaknesses:\n",
    "    print(f\"- {weakness}\")\n",
    "    \n",
    "print(\"\\nOpportunities:\")\n",
    "for opportunity in analysis_result.opportunities:\n",
    "    print(f\"- {opportunity}\")\n",
    "    \n",
    "print(\"\\nThreats:\")\n",
    "for threat in analysis_result.threats:\n",
    "    print(f\"- {threat}\")\n",
    "    \n",
    "print(f\"\\nRecommendation: {analysis_result.recommendation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deep Dive Analysis\n",
    "\n",
    "Let's run a deep dive analysis to get more detailed insights about the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run deep dive analysis\n",
    "deep_dive_result = await run_async(run_deep_dive_analysis(\n",
    "    scraped_data.company_name, \n",
    "    scraped_data.description, \n",
    "    scraped_data.raw_text\n",
    "))\n",
    "\n",
    "# Display deep dive sections\n",
    "print(\"Deep Dive Analysis Sections:\")\n",
    "for section, content in deep_dive_result.items():\n",
    "    print(f\"\\n{section.upper()}:\")\n",
    "    if isinstance(content, dict):\n",
    "        for key, value in content.items():\n",
    "            if isinstance(value, list):\n",
    "                print(f\"\\n{key}:\")\n",
    "                for item in value:\n",
    "                    print(f\"- {item}\")\n",
    "            else:\n",
    "                print(f\"\\n{key}: {value}\")\n",
    "    elif isinstance(content, list):\n",
    "        for item in content:\n",
    "            print(f\"- {item}\")\n",
    "    else:\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Founder Evaluation\n",
    "\n",
    "Finally, let's test the new founder evaluation feature to predict founder success based on scientific criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run founder evaluation\n",
    "founder_evaluation = await run_async(evaluate_founders(\n",
    "    scraped_data.company_name,\n",
    "    scraped_data.description,\n",
    "    scraped_data.team_info,\n",
    "    scraped_data.raw_text,\n",
    "    deep_dive_result\n",
    "))\n",
    "\n",
    "# Display founder evaluation results\n",
    "print(f\"Success Prediction: {founder_evaluation['success_prediction']}\")\n",
    "print(f\"\\nOverall Assessment: {founder_evaluation['overall_assessment']}\")\n",
    "\n",
    "print(\"\\nEvaluation Criteria:\")\n",
    "for criterion, data in founder_evaluation['evaluation_criteria'].items():\n",
    "    print(f\"\\n{criterion.replace('_', ' ').title()}:\")\n",
    "    print(f\"Score: {data['score']}/10\")\n",
    "    print(f\"Assessment: {data['assessment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Complete Analysis\n",
    "\n",
    "Now let's run a complete analysis with all features enabled at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run complete analysis\n",
    "complete_analysis = await run_async(analyze_data(\n",
    "    scraped_data, \n",
    "    [\"swot\", \"deep_dive\", \"founder_evaluation\"]\n",
    "))\n",
    "\n",
    "# Convert to JSON for better visualization\n",
    "analysis_json = json.loads(complete_analysis.json())\n",
    "\n",
    "# Display basic info\n",
    "print(f\"Company: {analysis_json['company_name']}\")\n",
    "print(f\"Industry: {analysis_json['industry']}\")\n",
    "print(f\"Score: {analysis_json['score']}/10\")\n",
    "print(f\"Analysis Types: {', '.join(analysis_json['analysis_types'])}\")\n",
    "\n",
    "# Save the complete analysis to a file\n",
    "with open(f\"{analysis_json['company_name'].lower()}_analysis.json\", \"w\") as f:\n",
    "    json.dump(analysis_json, f, indent=2)\n",
    "    \n",
    "print(f\"\\nComplete analysis saved to {analysis_json['company_name'].lower()}_analysis.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Multiple Startups\n",
    "\n",
    "Let's compare the founder evaluation results for multiple startups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def analyze_startup(url):\n",
    "    print(f\"Analyzing {url}...\")\n",
    "    scraped = await scrape_website(url)\n",
    "    analysis = await analyze_data(scraped, [\"swot\", \"founder_evaluation\"])\n",
    "    return {\n",
    "        \"company\": analysis.company_name,\n",
    "        \"score\": analysis.score,\n",
    "        \"success_prediction\": analysis.founder_evaluation.get(\"success_prediction\", False) if analysis.founder_evaluation else False,\n",
    "        \"top_strength\": analysis.strengths[0] if analysis.strengths else \"\",\n",
    "        \"top_weakness\": analysis.weaknesses[0] if analysis.weaknesses else \"\"\n",
    "    }\n",
    "\n",
    "# Analyze multiple startups\n",
    "results = []\n",
    "for url in test_urls:\n",
    "    result = await run_async(analyze_startup(url))\n",
    "    results.append(result)\n",
    "    \n",
    "# Display comparison table\n",
    "print(\"\\nStartup Comparison:\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"{'Company':<20} | {'Score':<5} | {'Success':<7} | {'Top Strength':<30} | {'Top Weakness':<30}\")\n",
    "print(\"-\" * 100)\n",
    "for result in results:\n",
    "    print(f\"{result['company']:<20} | {result['score']:<5} | {str(result['success_prediction']):<7} | {result['top_strength'][:30]:<30} | {result['top_weakness'][:30]:<30}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
